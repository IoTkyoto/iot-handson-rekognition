# スマートフォンとAWSサービスを用いた画像認識サービスを構築する

# はじめに

当コンテンツは、エッジデバイスとしてスマートフォン、クラウドサービスとしてAWSを利用し、エッジデバイスとクラウド間とのデータ連携とAWSサービスを利用した画像認識を体験し、IoT/画像認識システムの基礎的な技術の習得を目指す方向けのハンズオン(体験学習)コンテンツです。

## 全体のアーキテクチャ

今回のコンテンツ内で構築するIoTシステムの全体像です。

![全体アーキテクチャ図](https://s3.amazonaws.com/docs.iot.kyoto/img/Rekognition-Handson/architecture_overall.png)

### 今回のアーキテクチャの3つの大きなポイント

### ポイント1. 様々な手段によるクラウドサービスへのアクセス

- AWS Webコンソールでのクラウド操作
- AWS CLIを用いたクラウド操作
- AWS SDKを用いたデバイスとクラウドサービスの連携
- Web APIを用いたデバイスとクラウドサービスの連携

### ポイント2. AWSでの顔認証・ログ蓄積

- AWSの画像分析サービス「**[Amazon Rekognition](https://aws.amazon.com/jp/rekognition/)**」を使って、デバイスのカメラで取得した画像の分析や、画像に写っている人物が事前登録済みの人物かどうかの判定を行います
- AWSのIoTサービス「**[AWS IoT Core](https://aws.amazon.com/jp/iot-core)**」を使って、デバイスに接続されているセンサーから取得したデータや、各処理で生成されたログデータをクラウドに送信し、「**[Amazon S3](https://aws.amazon.com/jp/s3)**」に蓄積します

### ポイント3. アプリを利用した蓄積ログの分析・可視化

- AWSの高速BIサービス「**[Amazon QuickSight](https://aws.amazon.com/jp/quicksight/)**」を使って、各種ログデータの分析・可視化を行います


以上を通して、エッジで処理したデータのクラウド連携や画像認識サービス活用のノウハウを学びます。

## ハンズオンの前提条件

このハンズオンを行う上で必要な環境やスキルです。
下記条件を満たさない場合、うまくハンズオンが進められない場合がありますので、あらかじめご了承ください。

- Admin権限で利用できるAWSアカウントを所有していること
- AWSコンソールヘのログインや一般的な操作が可能であること
- Pythonで記述されたプログラムの読み書きができること
- JavaScriptで記述されたプログラムの読み書きができること
- 基本的なコマンドライン操作ができること
- ローカルPCのWebブラウザとして「Chrome」が利用可能であること

## ハンズオンの進め方

ハンズオンは、内容によって５つのステップに分割しています。
当ポータルサイトから各ステップの記事を新規タブで開いて、１つずつ進めてください。

またスマートフォン側で動かすVue.js(JavaScript)コードやLambdaのPythonコードのサンプルソースは[GitHubのリポジトリ](https://github.com/IoTkyoto/iot-handson-rekognition)で公開しています。
コンテンツ内でもご案内しますが、実装が必要なステップではこちらのサンプルソースをご活用ください。
コンテンツ内には実装に関わるヒントも掲載していますので、自力でコーディング出来る方は是非チャレンジしてみましょう。

# ステップ0. 環境準備

今回のハンズオンでは、エッジデバイスであるスマートフォンと、クラウド環境の構築やその他必要な作業を行うためのローカルPCが必要です。
ハンズオンを進めるにあたって必要な準備作業について説明します。

**以下のコンテンツを開き、ステップ0を進めてください**
※コンテンツは右クリックから新規タブで開いてください
https://github.com/IoTkyoto/iot-handson-rekognition/blob/master/contents/step0.md

# ステップ1. 顔認識用のコレクションを作成する

ステップ1では、画像に写っている人物を特定するために必要なコレクションを作成します。
AWS Rekognitionサービスでは、コレクションの情報を使って、画像内に誰が写っているのかを特定する機能があります。

まずは、画像のアップロード先として「[**Amazon S3（以下、S3）**](https://aws.amazon.com/jp/s3)」にバケットを作成し、登録したい人物が１人で写っている画像をAWSコンソールからアップロードします。

AWSのCLI(コマンド・ライン・インターフェース)ツールを使って、「**[Amazon Rekognition（以下、Rekognition）](https://aws.amazon.com/jp/rekognition/)**」の「コレクション」を作成し、認識対象となる顔を登録します。


**以下のコンテンツを開き、ステップ1を進めてください**
※コンテンツは右クリックから新規タブで開いてください
https://github.com/IoTkyoto/iot-handson-rekognition/blob/master/contents/step1.md

# ステップ2. 顔認証のWeb APIを作成する

ステップ2では、前ステップでS3バケットにアップロードされた画像を分析し「事前登録済みの人物が写っているかを判定し、写っている場合は誰なのかを判定する」という機能を持ったWeb APIを作成し、デバイス側からAPIを呼び出す仕組みを構築します。

**以下のコンテンツを開き、ステップ2を進めてください**
※コンテンツは右クリックから新規タブで開いてください
https://github.com/IoTkyoto/iot-handson-rekognition/blob/master/contents/step2.md

# ステップ3. 顔画像分析結果を取得するWeb APIを作成する

ステップ３では「画像に写っている人物の顔の特徴を分析する」機能を持ったWeb APIを作成し、デバイス側からAPIを呼び出す仕組みを構築します。
ステップ2の内容を参考にして仕組みを構築してください。詳細な手順は記載せず、実装のヒントのみ記載しております。

**以下のコンテンツを開き、ステップ3を進めてください**
※コンテンツは右クリックから新規タブで開いてください
https://github.com/IoTkyoto/iot-handson-rekognition/blob/master/contents/step3.md

# ステップ4. ログデータをクラウドにアップロードする

ステップ4では、前回までのステップでWeb APIから受け取った顔画像分析結果データを、クラウドに送信し蓄積する仕組みを構築します。
データを格納することで、次のステップでデータの可視化が行えるようになります。

顔画像分析ログデータについては、各所から集められる大量のストリーミングログデータを欠損なく扱うユースケースとして、[Amazon Kinesis Data Firehose](https://aws.amazon.com/jp/kinesis/data-firehose/)経由でデータの保存を行います。

今回の手順では、先にデータの格納先を準備し、次にルールを作成、最後にデバイスからログデータを送信するプログラムを作成します。

**以下のコンテンツを開き、ステップ4を進めてください**
※コンテンツは右クリックから新規タブで開いてください
https://github.com/IoTkyoto/iot-handson-rekognition/blob/master/contents/step4.md

# ステップ5. ログデータの可視化を行う

ステップ5では、今までのステップで収集しクラウドに保存したデータを可視化します。
今回のハンズオンでは、AWSが提供している高速なBIサービス「**Amazon QuickSight**（以下、QuickSight）」を使用しデータの可視化を行います。

**以下のコンテンツを開き、ステップ5を進めてください**
※コンテンツは右クリックから新規タブで開いてください
https://github.com/IoTkyoto/iot-handson-rekognition/blob/master/contents/step5.md

# さいごに

ご利用いただいたAWSの各種サービスには無料利用枠がございますが、無料利用枠を超えた場合は従量課金が発生します。
ハンズオンを行い、環境が不要となれば各種リソースを削除することを推奨します。











